{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOLzhC716ICgv3Mr9V+jg+B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivster2000/UROPs2025/blob/main/Bot-to-Bot_ControllableComplexityChatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Controllable Complexity Chatbot from Tyen (2022)\n",
        "\n",
        " - Connect to a GPU runtime for optimal inference times\n",
        " - Run all below cells, and the chatbot will load in the output of the demo.py cell"
      ],
      "metadata": {
        "id": "gSgACwIPWHjz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependencies"
      ],
      "metadata": {
        "id": "XnDEBPGSVd6U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1gQgTHS1INZ",
        "outputId": "4218a5d7-1b10-4c61-d2bc-371949f7cce1",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ControllableComplexityChatbot'...\n",
            "remote: Enumerating objects: 69, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 69 (delta 28), reused 26 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (69/69), 1.13 MiB | 4.85 MiB/s, done.\n",
            "Resolving deltas: 100% (28/28), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shivster2000/ControllableComplexityChatbot.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/ControllableComplexityChatbot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_Be0IPS2YX0",
        "outputId": "a1c5f095-5406-4ba0-fafa-3b2340d0d486",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ControllableComplexityChatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy scipy regex torch transformers iopath"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgSGHYGC2k0l",
        "outputId": "e03cc6bd-6df2-453e-bbf9-513c099d7ae8",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Collecting portalocker (from iopath)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: iopath\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=190dfb68fe88bae2dba58c093e108c0cb87d135e246e3f595af6cb8cb2d7a52d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
            "Successfully built iopath\n",
            "Installing collected packages: portalocker, iopath\n",
            "Successfully installed iopath-0.1.10 portalocker-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install ParlAI"
      ],
      "metadata": {
        "id": "0n__pJp7VqY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/ParlAI.git --branch 1.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHo7K5zi352u",
        "outputId": "fc6fd451-2946-4d38-a3d6-d649abc7206e",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ParlAI'...\n",
            "remote: Enumerating objects: 48019, done.\u001b[K\n",
            "remote: Total 48019 (delta 0), reused 0 (delta 0), pack-reused 48019 (from 1)\u001b[K\n",
            "Receiving objects: 100% (48019/48019), 145.65 MiB | 19.28 MiB/s, done.\n",
            "Resolving deltas: 100% (34129/34129), done.\n",
            "Note: switching to '054a0fff8183e357727dc7a91682496734badb7f'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6010796e",
        "outputId": "b5d00228-1f83-44cb-bc11-4b98735eec98",
        "collapsed": true
      },
      "source": [
        "!pip install git+https://github.com/facebookresearch/ParlAI.git@1.6.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/ParlAI.git@1.6.0\n",
            "  Cloning https://github.com/facebookresearch/ParlAI.git (to revision 1.6.0) to /tmp/pip-req-build-fymhowu6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/ParlAI.git /tmp/pip-req-build-fymhowu6\n",
            "  Running command git checkout -q 054a0fff8183e357727dc7a91682496734badb7f\n",
            "  Resolved https://github.com/facebookresearch/ParlAI.git to commit 054a0fff8183e357727dc7a91682496734badb7f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from parlai==1.6.0)\n",
            "  Downloading boto3-1.40.24-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting botocore (from parlai==1.6.0)\n",
            "  Downloading botocore-1.40.24-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting coloredlogs (from parlai==1.6.0)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: datasets>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (4.0.0)\n",
            "Collecting docutils<0.16,>=0.14 (from parlai==1.6.0)\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting emoji (from parlai==1.6.0)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting fairscale~=0.4.1 (from parlai==1.6.0)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docformatter (from parlai==1.6.0)\n",
            "  Downloading docformatter-1.7.7-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting flake8-bugbear (from parlai==1.6.0)\n",
            "  Downloading flake8_bugbear-24.12.12-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting flake8 (from parlai==1.6.0)\n",
            "  Downloading flake8-7.3.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (2.19.0)\n",
            "Collecting importlib-metadata<4.3 (from parlai==1.6.0)\n",
            "  Downloading importlib_metadata-4.2.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: iopath~=0.1.8 in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (0.1.10)\n",
            "Collecting gitdb2 (from parlai==1.6.0)\n",
            "  Downloading gitdb2-4.0.2-py3-none-any.whl.metadata (383 bytes)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (3.1.45)\n",
            "Collecting hydra-core~=1.1.0 (from parlai==1.6.0)\n",
            "  Downloading hydra_core-1.1.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (7.34.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (3.9.1)\n",
            "Collecting omegaconf~=2.1.1 (from parlai==1.6.0)\n",
            "  Downloading omegaconf-2.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (2.2.2)\n",
            "Collecting pytest_regressions (from parlai==1.6.0)\n",
            "  Downloading pytest_regressions-2.8.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (8.4.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (4.9.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (11.3.0)\n",
            "Collecting py-gfm (from parlai==1.6.0)\n",
            "  Downloading py_gfm-2.0.0-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting py-rouge (from parlai==1.6.0)\n",
            "  Downloading py_rouge-1.1-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (6.0.2)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (26.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (2024.11.6)\n",
            "Collecting myst-parser~=0.12.2 (from parlai==1.6.0)\n",
            "  Downloading myst_parser-0.12.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting attrs~=20.2.0 (from parlai==1.6.0)\n",
            "  Downloading attrs-20.2.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting requests-mock (from parlai==1.6.0)\n",
            "  Downloading requests_mock-1.12.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (2.32.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (1.16.1)\n",
            "Collecting sh (from parlai==1.6.0)\n",
            "  Downloading sh-2.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx_rtd_theme (from parlai==1.6.0)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting sphinx-autodoc-typehints~=1.10.3 (from parlai==1.6.0)\n",
            "  Downloading sphinx_autodoc_typehints-1.10.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting Sphinx~=2.2.0 (from parlai==1.6.0)\n",
            "  Downloading Sphinx-2.2.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting subword-nmt (from parlai==1.6.0)\n",
            "  Downloading subword_nmt-0.3.8-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (2.19.0)\n",
            "Collecting tensorboardX (from parlai==1.6.0)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: tokenizers>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (0.22.0)\n",
            "Collecting tomli<2.0.0 (from parlai==1.6.0)\n",
            "  Downloading tomli-1.2.3-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting torchtext>=0.5.0 (from parlai==1.6.0)\n",
            "  Downloading torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (6.4.2)\n",
            "Collecting tqdm~=4.62.1 (from parlai==1.6.0)\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (4.15.0)\n",
            "Collecting Unidecode (from parlai==1.6.0)\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (2.5.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.12/dist-packages (from parlai==1.6.0) (1.8.0)\n",
            "Collecting websocket-server (from parlai==1.6.0)\n",
            "  Downloading websocket_server-0.6.4-py3-none-any.whl.metadata (359 bytes)\n",
            "Collecting jsonlines (from parlai==1.6.0)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting numpy<=1.21 (from parlai==1.6.0)\n",
            "  Downloading numpy-1.21.0.zip (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n",
            "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n",
            "    return any(self)\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "                       ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 53, in _iter_built\n",
            "    candidate = func()\n",
            "                ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 185, in _make_candidate_from_link\n",
            "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 642, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 56, in prepare_distribution_metadata\n",
            "    self._install_build_reqs(finder)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 126, in _install_build_reqs\n",
            "    build_reqs = self._get_build_requires_wheel()\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 103, in _get_build_requires_wheel\n",
            "    return backend.get_requires_for_build_wheel()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/misc.py\", line 709, in get_requires_for_build_wheel\n",
            "    return super().get_requires_for_build_wheel(config_settings=cs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 166, in get_requires_for_build_wheel\n",
            "    return self._call_hook('get_requires_for_build_wheel', {\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 321, in _call_hook\n",
            "    raise BackendUnavailable(data.get('traceback', ''))\n",
            "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 77, in _build_backend\n",
            "    obj = import_module(mod_path)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/tmp/pip-build-env-w2o_1qh8/overlay/local/lib/python3.12/dist-packages/setuptools/__init__.py\", line 18, in <module>\n",
            "    from setuptools.extern.six import PY3, string_types\n",
            "ModuleNotFoundError: No module named 'setuptools.extern.six'\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below cell **will** give an error - ignore this; the chatbot seems not to run properly without running this command"
      ],
      "metadata": {
        "id": "FMWMTrJxV00B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ParlAI; python setup.py develop; cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHmfoxZX4EAN",
        "outputId": "cda5d625-feab-4044-9158-220950ad93e0",
        "collapsed": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/command/develop.py:41: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating parlai.egg-info\n",
            "writing parlai.egg-info/PKG-INFO\n",
            "writing dependency_links to parlai.egg-info/dependency_links.txt\n",
            "writing entry points to parlai.egg-info/entry_points.txt\n",
            "writing requirements to parlai.egg-info/requires.txt\n",
            "writing top-level names to parlai.egg-info/top_level.txt\n",
            "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "reading manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.12/dist-packages/parlai.egg-link (link to .)\n",
            "Adding parlai 1.6.0 to easy-install.pth file\n",
            "Installing parlai script to /usr/local/bin\n",
            "\n",
            "Installed /content/ControllableComplexityChatbot/ParlAI\n",
            "Processing dependencies for parlai==1.6.0\n",
            "Searching for markdown<=3.3.2\n",
            "Reading https://pypi.org/simple/markdown/\n",
            "Downloading https://files.pythonhosted.org/packages/a0/34/4d6b7e3044044e89eaa25ed5395656cc351163c625fda0656d2729de399f/Markdown-3.3.2-py3-none-any.whl#sha256=77b7bff443b1f97b4814fa438c181fd5882e31edb01b422856b3feca91475f3e\n",
            "Best match: Markdown 3.3.2\n",
            "Processing Markdown-3.3.2-py3-none-any.whl\n",
            "Installing Markdown-3.3.2-py3-none-any.whl to /usr/local/lib/python3.12/dist-packages\n",
            "Adding Markdown 3.3.2 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.12/dist-packages/Markdown-3.3.2-py3.12.egg\n",
            "Searching for numpy<=1.21\n",
            "Reading https://pypi.org/simple/numpy/\n",
            "Downloading https://files.pythonhosted.org/packages/66/03/818876390c7ff4484d5a05398a618cfdaf0a2b9abb3a7c7ccd59fe181008/numpy-1.21.0.zip#sha256=e80fe25cba41c124d04c662f33f6364909b985f2eb5998aaa5ae4b9587242cce\n",
            "Best match: numpy 1.21.0\n",
            "Processing numpy-1.21.0.zip\n",
            "Writing /tmp/easy_install-1r6wpkqp/numpy-1.21.0/setup.cfg\n",
            "Running numpy-1.21.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-1r6wpkqp/numpy-1.21.0/egg-dist-tmp-qjm7gtwy\n",
            "/tmp/easy_install-1r6wpkqp/numpy-1.21.0/setup.py:63: RuntimeWarning: NumPy 1.21.0 may not yet support Python 3.12.\n",
            "  warnings.warn(\n",
            "Running from numpy source directory.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 165, in save_modules\n",
            "    yield saved\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 207, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 268, in run_setup\n",
            "    _execfile(setup_script, ns)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 50, in _execfile\n",
            "    exec(code, globals, locals)\n",
            "  File \"/tmp/easy_install-1r6wpkqp/numpy-1.21.0/setup.py\", line 82, in <module>\n",
            "  File \"/tmp/easy_install-1r6wpkqp/numpy-1.21.0/numpy/distutils/core.py\", line 24, in <module>\n",
            "  File \"/tmp/easy_install-1r6wpkqp/numpy-1.21.0/numpy/distutils/command/config.py\", line 19, in <module>\n",
            "  File \"/tmp/easy_install-1r6wpkqp/numpy-1.21.0/numpy/distutils/mingw32ccompiler.py\", line 29, in <module>\n",
            "ModuleNotFoundError: No module named 'distutils.msvccompiler'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ControllableComplexityChatbot/ParlAI/setup.py\", line 29, in <module>\n",
            "    setup(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/__init__.py\", line 117, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/core.py\", line 183, in setup\n",
            "    return run_commands(dist)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/core.py\", line 199, in run_commands\n",
            "    dist.run_commands()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/dist.py\", line 954, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/dist.py\", line 991, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/_distutils/dist.py\", line 973, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/develop.py\", line 35, in run\n",
            "    self.install_for_development()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/develop.py\", line 127, in install_for_development\n",
            "    self.process_distribution(None, self.dist, not self.no_deps)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/easy_install.py\", line 788, in process_distribution\n",
            "    distros = WorkingSet([]).resolve(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pkg_resources/__init__.py\", line 897, in resolve\n",
            "    dist = self._resolve_dist(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pkg_resources/__init__.py\", line 933, in _resolve_dist\n",
            "    dist = best[req.key] = env.best_match(\n",
            "                           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pkg_resources/__init__.py\", line 1271, in best_match\n",
            "    return self.obtain(req, installer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pkg_resources/__init__.py\", line 1307, in obtain\n",
            "    return installer(requirement) if installer else None\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/easy_install.py\", line 712, in easy_install\n",
            "    return self.install_item(spec, dist.location, tmpdir, deps)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/easy_install.py\", line 737, in install_item\n",
            "    dists = self.install_eggs(spec, download, tmpdir)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/easy_install.py\", line 934, in install_eggs\n",
            "    return self.build_and_install(setup_script, setup_base)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/easy_install.py\", line 1206, in build_and_install\n",
            "    self.run_setup(setup_script, setup_base, args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/command/easy_install.py\", line 1192, in run_setup\n",
            "    run_setup(setup_script, args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 258, in run_setup\n",
            "    with setup_context(setup_dir):\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
            "    self.gen.throw(value)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 199, in setup_context\n",
            "    with save_modules():\n",
            "         ^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
            "    self.gen.throw(value)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 178, in save_modules\n",
            "    saved_exc.resume()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 152, in resume\n",
            "    raise exc.with_traceback(self._tb)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 165, in save_modules\n",
            "    yield saved\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 207, in setup_context\n",
            "    yield\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 268, in run_setup\n",
            "    _execfile(setup_script, ns)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/setuptools/sandbox.py\", line 50, in _execfile\n",
            "    exec(code, globals, locals)\n",
            "  File \"/tmp/easy_install-1r6wpkqp/numpy-1.21.0/setup.py\", line 82, in <module>\n",
            "  File \"/tmp/easy_install-1r6wpkqp/numpy-1.21.0/numpy/distutils/core.py\", line 24, in <module>\n",
            "  File \"/tmp/easy_install-1r6wpkqp/numpy-1.21.0/numpy/distutils/command/config.py\", line 19, in <module>\n",
            "  File \"/tmp/easy_install-1r6wpkqp/numpy-1.21.0/numpy/distutils/mingw32ccompiler.py\", line 29, in <module>\n",
            "ModuleNotFoundError: No module named 'distutils.msvccompiler'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ControllableComplexityChatbot/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3prWa3BQ6rXm",
        "outputId": "e6c15b98-149c-4eb9-90cd-ac26629ba01f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ControllableComplexityChatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run Demo"
      ],
      "metadata": {
        "id": "w8Q4xAq8VvGw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDYjv6s8_GKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "%cd /content/ControllableComplexityChatbot/ParlAI\n",
        "from parlai.zoo.blender.blender_3B import download\n",
        "from parlai.core.opt import Opt\n",
        "\n",
        "%cd /content/ControllableComplexityChatbot/\n",
        "from controllable_blender import ControllableBlender\n",
        "\n",
        "agent_opt = json.load(open(\"blender_3B.opt\", 'r'))\n",
        "\n",
        "# Set to \"vocab\" for vocabulary restriction, \"rerank\" for candidate reranking\n",
        "agent_opt[\"inference\"] = \"rerank\"\n",
        "# Same top-k sampling configs for all settings described in the paper\n",
        "agent_opt[\"beam_size\"] = 20\n",
        "agent_opt[\"topk\"] = 40\n",
        "\n",
        "# Settings for rerank methods (not used if \"inference\" == \"vocab\")\n",
        "agent_opt[\"rerank_cefr\"] = \"B1\"                       # CEFR level to adjust reranking. Possible values: ['A2', 'B1', 'B2', 'C1', 'C2'].\n",
        "agent_opt[\"rerank_tokenizer\"] = \"distilroberta-base\"        # Tokenizer from Huggingface Transformers. Must be compatible with \"rerank_model\"\n",
        "agent_opt[\"rerank_model\"] = \"complexity_model\"              # Model fine-tuned on complexity data\n",
        "agent_opt[\"rerank_model_device\"] = \"cuda\"                   # Device for complexity model\n",
        "agent_opt[\"penalty_stddev\"] = 2                             # Controls how harshly sub-tokens are penalised (lower = harsher). Use -1 to remove penalties\n",
        "agent_opt[\"filter_path\"] = \"data/filter.txt\"                # Path to list of English words to ensure OOV words are not generated. Capitalised words are ignored. Use empty string to remove filter\n",
        "\n",
        "# Settings for vocab methods (not used if \"inference\" == \"rerank\")\n",
        "agent_opt[\"wordlist_path\"] = \"data/sample_wordlist.txt\"          # Path to list of vocab the chatbot is restricted to\n",
        "\n",
        "\n",
        "download(agent_opt[\"datapath\"])\n",
        "\n",
        "agent = ControllableBlender(agent_opt)\n",
        "\n",
        "#import baby model\n",
        "from transformers import AutoTokenizer, LlamaForCausalLM\n",
        "from parlai.core.agents import Agent\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "#climb-mao/babylm-B1-fine-tuned\n",
        "\n",
        "#instantiate your model here\n",
        "class TransformersAgentWrapper(Agent):\n",
        "    def __init__(self, opt, model_name=\"climb-mao/babylm-A-fine-tuned\", max_new_tokens=60):\n",
        "        super().__init__(opt)\n",
        "        self.id = \"A-Learner\"\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # Load tokenizer + model\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            model_name,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            trust_remote_code=True\n",
        "        ).to(self.device)\n",
        "\n",
        "        self.max_new_tokens = 60\n",
        "        self.context = \"\"\n",
        "\n",
        "    def observe(self, observation):\n",
        "        if 'episode_done' not in observation:\n",
        "            observation = observation.copy()  # avoid mutating input dict\n",
        "            observation['episode_done'] = False\n",
        "        self.observation = observation\n",
        "        if not observation.get(\"episode_done\", False):\n",
        "            speaker = \"Teacher\" if observation.get(\"from\") == \"teacher\" else \"Student\"\n",
        "            self.context += f\"\\n{speaker}: {observation.get('text', '')}\"\n",
        "\n",
        "    def act(self):\n",
        "        system_instruction = \"You are a student. Respond in a maximum of two short sentences.\"\n",
        "        prompt = f\"{self.context}\\nStudent:\"\n",
        "        inputs = self.tokenizer(\n",
        "            system_instruction + \"\\n\" + prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        ).to(self.device)\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_new_tokens,\n",
        "            pad_token_id=self.tokenizer.pad_token_id,\n",
        "            eos_token_id=self.tokenizer.eos_token_id,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        full_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        reply = full_text.split(\"Student:\")[-1].strip()\n",
        "\n",
        "        # Trim to max 2 sentences\n",
        "        sentences = reply.replace(\"\\n\", \" \").split(\". \")\n",
        "        reply = \". \".join(sentences[:2]).strip()\n",
        "        if not reply.endswith(\".\"):\n",
        "            reply += \".\"\n",
        "\n",
        "        self.context += f\"\\nStudent: {reply}\"\n",
        "        return {\"id\": self.id, \"text\": reply}\n",
        "\n",
        "from parlai.core.params import ParlaiParser\n",
        "from parlai.core.worlds import DialogPartnerWorld\n",
        "from controllable_blender import ControllableBlender\n",
        "\n",
        "class TwoBotDialogPartnerWorld(DialogPartnerWorld):\n",
        "    def __init__(self, opt, agent1, agent2, max_turns=5):\n",
        "        super().__init__(opt, [agent1, agent2])\n",
        "        self.turns = 0\n",
        "        self.max_turns = max_turns\n",
        "\n",
        "    def parley(self):\n",
        "        acts = []\n",
        "        for idx, agent in enumerate(self.agents):\n",
        "            # First agent's turn\n",
        "            if idx == 0 and self.turns == 0:\n",
        "                text = \"The teacher greets you. Respond as the student.\"\n",
        "                obs = {\"text\": text, \"episode_done\": False, \"from\": \"teacher\"}\n",
        "            else:\n",
        "                # Use the last message from the other agent\n",
        "                text = acts[-1]['text'] if acts else \"\"\n",
        "                obs = {\"text\": text, \"episode_done\": False, \"from\": \"teacher\" if idx == 1 else \"student\"}\n",
        "\n",
        "            obs = {\"text\": text, \"episode_done\": False}\n",
        "            agent.observe(obs)\n",
        "            acts.append(agent.act())\n",
        "\n",
        "        self.acts = acts\n",
        "        for m in acts:\n",
        "            print(f\"{m['id']}: {m.get('text', '')}\")\n",
        "\n",
        "        self.turns += 1\n",
        "\n",
        "    def episode_done(self):\n",
        "        return self.turns >= self.max_turns\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = ParlaiParser()\n",
        "    opt = parser.parse_args([])\n",
        "\n",
        "    # Instantiate agents\n",
        "    hf_agent = TransformersAgentWrapper(opt, model_name=\"climb-mao/babylm-A-fine-tuned\")\n",
        "    parlai_agent = agent\n",
        "\n",
        "    # Create and run world\n",
        "    world = TwoBotDialogPartnerWorld(opt, hf_agent, parlai_agent, max_turns=5)\n",
        "\n",
        "    while not world.episode_done():\n",
        "        world.parley()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9SaLWJVUT5Y",
        "outputId": "3e3e766c-6a4e-4809-ad9d-fc47c58f6c4a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ControllableComplexityChatbot/ParlAI\n",
            "/content/ControllableComplexityChatbot\n",
            "23:39:22 INFO | Using CUDA\n",
            "23:39:22 INFO | loading dictionary from ParlAI/data/models/blender/blender_3B/model.dict\n",
            "23:39:22 INFO | num words = 8008\n",
            "23:40:11 INFO | Total parameters: 2,696,268,800 (2,695,613,440 trainable)\n",
            "23:40:11 INFO | Loading existing model params from ParlAI/data/models/blender/blender_3B/model\n",
            "A-Learner: the teacher's work. Also, there are a lot of interesting things for them.\n",
            "ControllableBlender: I have heard that in some countries teachers are highly respected, which is a good thing! \n",
            "A-Learner: the book, the school and the history of the old students. Interests and activities: play basketball, and play the piano.scenter: Get some music at the cinema and watch a movie.\n",
            "ControllableBlender: That's very true! The role of teacher varies a lot across the world, too. \n",
            "A-Learner: Im really enjoy the people, it is a great way to me!\u0014: a bit boring time, we can know how to play something and learn some different things, because it can become a great, like a good way to a way to know, and we can know what you want to achieve.\n",
            "ControllableBlender: I totally agree! People seem to think that teachers are always boring, but really they can be super engaging.\n",
            "A-Learner: too!\"@lither was not only at home, we can become a doctor, and have a great teacher at the class, that will become a great friends in a great way to be a doctor, and know, and they like that time to begin the university and find a great life,.\n",
            "ControllableBlender: That is a great point! They could help so many students achieve success they would never have had otherwise.\n",
            "A-Learner: I've done my father, and it was a big hug for me, it's a beautiful person at a beautiful stories. There are a great friends, and I think about a lot of a great person who will have a great party will make a happy life will help people that can make a great.\n",
            "ControllableBlender: That is so true. I want to be able to make a big impact in someones life.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Below Script deprecated manual version"
      ],
      "metadata": {
        "id": "blWq5j7iwbX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "%cd /content/ControllableComplexityChatbot/ParlAI\n",
        "from parlai.zoo.blender.blender_3B import download\n",
        "from parlai.core.opt import Opt\n",
        "\n",
        "%cd /content/ControllableComplexityChatbot/\n",
        "from controllable_blender import ControllableBlender\n",
        "from demo_utils import start_interaction\n",
        "\n",
        "agent_opt = json.load(open(\"blender_3B.opt\", 'r'))\n",
        "\n",
        "# Set to \"vocab\" for vocabulary restriction, \"rerank\" for candidate reranking\n",
        "agent_opt[\"inference\"] = \"rerank\"\n",
        "# Same top-k sampling configs for all settings described in the paper\n",
        "agent_opt[\"beam_size\"] = 20\n",
        "agent_opt[\"topk\"] = 40\n",
        "\n",
        "# Settings for rerank methods (not used if \"inference\" == \"vocab\")\n",
        "agent_opt[\"rerank_cefr\"] = \"B2\"                       # CEFR level to adjust reranking. Possible values: ['A2', 'B1', 'B2', 'C1', 'C2'].\n",
        "agent_opt[\"rerank_tokenizer\"] = \"distilroberta-base\"        # Tokenizer from Huggingface Transformers. Must be compatible with \"rerank_model\"\n",
        "agent_opt[\"rerank_model\"] = \"complexity_model\"              # Model fine-tuned on complexity data\n",
        "agent_opt[\"rerank_model_device\"] = \"cuda\"                   # Device for complexity model\n",
        "agent_opt[\"penalty_stddev\"] = 2                             # Controls how harshly sub-tokens are penalised (lower = harsher). Use -1 to remove penalties\n",
        "agent_opt[\"filter_path\"] = \"data/filter.txt\"                # Path to list of English words to ensure OOV words are not generated. Capitalised words are ignored. Use empty string to remove filter\n",
        "\n",
        "# Settings for vocab methods (not used if \"inference\" == \"rerank\")\n",
        "agent_opt[\"wordlist_path\"] = \"data/sample_wordlist.txt\"          # Path to list of vocab the chatbot is restricted to\n",
        "\n",
        "\n",
        "download(agent_opt[\"datapath\"])\n",
        "\n",
        "agent = ControllableBlender(agent_opt)\n",
        "\n",
        "#import baby model\n",
        "from transformers import AutoTokenizer, LlamaForCausalLM\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\"timinar/baby-llama-58m\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"timinar/baby-llama-58m\")\n",
        "\n",
        "student_persona = (\n",
        "    \"You are a curious student who loves talking about travel and music.\"\n",
        ")\n",
        "print(\"\\n==== Starting 5-Turn Interaction ====\\n\")\n",
        "\n",
        "for turn in range(1, 6):\n",
        "    print(f\"\\n--- Turn {turn} ---\")\n",
        "\n",
        "    if turn == 1:\n",
        "        # Start with an opening for Baby LLaMA\n",
        "        llama_prompt = (\n",
        "            f\"{student_persona}\\nThe teacher greets you. Respond as the student.\"\n",
        "        )\n",
        "    else:\n",
        "        # Craft a new prompt using last Blender reply\n",
        "        llama_prompt = (\n",
        "            f\"{student_persona}\\n\"\n",
        "            f\"Teacher just said: \\\"{blender_response}\\\"\\n\"\n",
        "            \"Reply as the student with curiosity or sharing your own view.\"\n",
        "        )\n",
        "\n",
        "    # Baby LLaMA generates a prompt\n",
        "    inputs = tokenizer(llama_prompt, return_tensors=\"pt\", truncation=True, max_length=256)\n",
        "    input_ids = inputs.input_ids\n",
        "\n",
        "    gen_ids = model.generate(\n",
        "        input_ids,\n",
        "        max_length=input_ids.shape[1] + 80,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.8,\n",
        "        eos_token_id=tokenizer.encode(\"\\nTeacher:\", add_special_tokens=False)[0]\n",
        "    )\n",
        "    generated_tokens = gen_ids[0][input_ids.shape[1]:]\n",
        "    student_prompt = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "    print(f\"Baby LLaMA: {student_prompt}\")\n",
        "\n",
        "    # Controllable Blender responds\n",
        "    agent.observe({\"text\": student_prompt, \"episode_done\": False})\n",
        "    blender_output = agent.act()\n",
        "\n",
        "if \"text\" not in blender_output:\n",
        "    print(f\"[DEBUG] No text in Blender output: {blender_output}\")\n",
        "    blender_response = \"[No response generated]\"\n",
        "else:\n",
        "    blender_response = blender_output[\"text\"]\n",
        "\n",
        "print(f\"ControllableBlender: {blender_response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "RwCW0UI5vW1u",
        "outputId": "4c32cca2-0a97-493d-aa56-62eb740d8fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ControllableComplexityChatbot/ParlAI\n",
            "/content/ControllableComplexityChatbot\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3797264169.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/ControllableComplexityChatbot/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcontrollable_blender\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControllableBlender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdemo_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstart_interaction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ControllableComplexityChatbot/controllable_blender/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontrollable_blender\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControllableBlender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/ControllableComplexityChatbot/controllable_blender/controllable_blender.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparlai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerGeneratorAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeneration_methods\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVocabTopKSampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRerankedTopKSampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeneration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReranker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_wordlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcefr_to_int\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ControllableComplexityChatbot/controllable_blender/generation_methods.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparlai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mneginf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeneration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReranker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWordlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVocabTopKSampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTopKSampling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ControllableComplexityChatbot/controllable_blender/generation_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mparlai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionaryAgent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobertaForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRobertaTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcefr_to_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcefr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2290\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2292\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2293\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2320\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mgeneration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerationMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_attn_mask_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_prepare_4d_attention_mask_for_sdpa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_prepare_4d_causal_attention_mask_for_sdpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mmodeling_layers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientCheckpointingLayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m from ...modeling_outputs import (\n\u001b[1;32m     33\u001b[0m     \u001b[0mBaseModelOutputWithPastAndCrossAttentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformersKwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_docstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_return_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodeling_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedAudioTokenizerBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torchao_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInt4WeightOnlyConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfiguration_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Skipping import of cpp extensions: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m from torchao.quantization import (\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mautoquant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mquantize_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/quantization/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from .autoquant import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mALL_AUTOQUANT_CLASS_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mDEFAULT_AUTOQUANT_CLASS_LIST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/quantization/autoquant.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from torchao.dtypes import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mAffineQuantizedTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mFloat8Layout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/dtypes/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maffine_quantized_tensor_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m from .affine_quantized_tensor import (\n\u001b[1;32m      3\u001b[0m     \u001b[0mAffineQuantizedTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mto_affine_quantized_floatx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mto_affine_quantized_floatx_static\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/dtypes/affine_quantized_tensor_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mAffineQuantizedTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m from torchao.dtypes.floatx.cutlass_semi_sparse_layout import (\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0m_linear_fp8_act_fp8_weight_sparse_cutlass_check\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0m_linear_fp8_act_fp8_weight_sparse_cutlass_impl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/dtypes/floatx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mCutlassSemiSparseLayout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfloat8_layout\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloat8Layout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m from .floatx_tensor_core_layout import (\n\u001b[1;32m      6\u001b[0m     \u001b[0mFloatxTensorCoreLayout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/dtypes/floatx/float8_layout.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAQTTensorImpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_out_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m from torchao.float8.inference import (\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mFloat8MMConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0m_is_rowwise_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/float8/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mScalingType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m from torchao.float8.float8_linear_utils import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mconvert_to_float8_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/float8/float8_linear_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloat8LinearConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8_linear\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloat8Linear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/float8/float8_linear.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloat8LinearConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalingGranularity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mScalingType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_already_casted_to_fp8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m from torchao.float8.float8_scaling_utils import (\n\u001b[1;32m     18\u001b[0m     \u001b[0mget_maybe_axiswise_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchao/float8/distributed_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functional_collectives\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfuncol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFloat8Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/_tensor/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfull_module_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"torch.distributed.tensor.{submodule}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     sys.modules[f\"torch.distributed._tensor.{submodule}\"] = import_module(\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mfull_module_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     )\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/tensor/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext_parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_map\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlocal_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_sharding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_sharding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}